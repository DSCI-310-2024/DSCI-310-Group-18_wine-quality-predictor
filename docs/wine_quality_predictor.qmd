---
title: "Predicting Wine Quality Score (Group 18)"
author: "Sid Ahuja, Xander Dawson, Zackarya Hamza"
format: 
    html: 
        toc: true
        toc-depth: 3
        embed-resources: true
    pdf:
        toc: true
        toc-depth: 3
        embed-resources: true
bibliography: references.bib 
execute: 
    echo: false
editor: source
---

```{r}
suppressPackageStartupMessages(library(tidyverse))
suppressPackageStartupMessages(library(tidymodels))
suppressPackageStartupMessages(library(repr))
suppressPackageStartupMessages(library(psych))
suppressPackageStartupMessages(library(kknn))
```

## Summary

In this report we attempt to build a k-nearest neighbors (k-nn) classification model which predicts the quality of a Portuguese white wine based on its chemical components and physical properties. The dataset classified the wine qualities on a 10-point scale which we transformed to a binary classification problem where wines with scores of 0-5 are considered low-quality and scores of 6-10 are considered high-quality. Our final model had an accuracy of 0.77, correctly predicting 77% of the test set samples. It did a better job at correctly predicting good quality wines than bad quality wines with a recall score of 0.89. While this model can definitely be improved upon, the implications of incorrect predictions are not very harmful. Additionally, it is likely that this model will not be used solely to make decisions about wine quality and production, but rather be used alongside with other tools and rankings by professional sommeliers as well as personal preferences of consumers. With this, we believe this model can be used to make predictions about Portuguese white wines but will require further training to be used on other wines.

## Introduction

Portugal is internationally recognized for its exceptional wines and booming wine industry. This distinction is rooted in the countryâ€™s rich viniculture history and its diverse climatic conditions, which contribute to the production of wines with unique flavors and aromas. However, with the wine market becoming increasingly saturated and competitive, the ability to accurately assess the quality of wine based on objective measurements has become highly valuable. The quality of a wine is heavily influenced by its various chemical components and physical properties and such features can be used to predict the quality of a wine [@wine_relevant_atts].

In this report, we aim to explore the application of machine learning algorithms in predicting the quality of Portuguese white wines, based on their chemical compositions and physical properties. Our goal is to develop a predictive model that can distinguish between high and low-quality wines with a high degree of accuracy. The significance of such a model lies in its potential to provide consumers with quality predictions prior to purchase as well as provide produced with information on ways to improve their wines; our model should be particularly good at identifying good wines to provide such information to manufacturers. Through the application of machine learning, this study contributes to the growing field of data-driven approaches in food science and quality assurance, marking a step towards the integration of technology and quality wine production.

## Methods

### Data

In order to explore and build a wine quality classification model, we are using the wine quality data set sourced from the [UCI Machine Learning Repository](https://archive.ics.uci.edu/dataset/186/wine+quality) and created by P. Cortez, A. Cerdeira, F. Almeida, T. Matos and J. Reis from the University of Minho in Portugal [@wine_quality]. Specifically, we are interested in predicting white wine quality based on the chemical composition of the wine. Each row represents a white wine and the chemical measurements taken from the wine and there are 4898 samples in the dataset. The target value (integer wine quality score) was determined by the Vinho Verde Wine Commission (CVRVV) of Portugal [@vinho_verde].

| Feature | Type | Description|
|:---:|:---:|:---:|
| Fixed Acitity | Coninuous | Concentration (g/L) of tartaric acid.<br />Impacts the tartness of wines. |
| Volatile Acitity | Coninuous | Concentration (g/L) of acetic acid.<br />Impacts the vinegar-like taste in wines. |
| Citric Acid | Coninuous | Concentration (g/L) of citric acid.<br />Impacts the freshness of wines. |
| Residual Sugar | Coninuous | Concentration (g/L) of sugar remaining after fermentation.<br />Impacts the sweetness of wines. |
| Chlorides | Coninuous | Concentration (g/L) of chlorides.<br />Impacts the saltiness of wines. |
| Free Sulfur Dioxide | Coninuous | Concentration (mg/L) of unbound SO2.<br />Prevents microbial growth. |
| Total Sulfur Dioxide | Coninuous | Concentration (mg/L) of total SO2.<br />Prevents microbial growth and impacts aroma/taste. |
| Density | Coninuous | Density (g/mL) measurement.<br />Relates alcohol to sugar content. |
| pH | Coninuous | Measurement of wine acidity. | 
| Suphates | Coninuous | Concentration (mg/L) of total sulphates. |
| Alcohol | Coninuous | Percentage (%) of alcohol content. |
: Column Descriptions {#tbl-cols}

### Analysis

To predict the wine quality, we utilized the k-nearest neighbors (k-nn) algorithm and built a classification model based on certain features within the dataset (specifically alcohol, volatile acidity, total sulfur dioxide content, density, chlorides, and residual sugar of the wines). First we converted the quality_score target column into a quality_class column where scores 0-5 were considered bad and scores 6-10 were considered good. We did this to reduce the number of target classes (creating a binary classification problem) as well as to allow for more examples within each class. Then we split the data into train (70%) and test splits (30%). All selected features were scaled prior to model training. We selected the features based on a qualitative analysis of their distribution for each class; features that greatly overlapped across classes were dropped. Then, the best value for hyperparameter K was determined using a 10-fold cross-validation test. For this model, we determined accuracy to be the best measurement/metric for assessing our model as there are a similar number of samples within each class. For the confusion matrix metrics, we consider good to be the positive category and bad to be the negative category. The R programming language [@R] and the following packages were used to perform the analysis: tidyverse [@tidyverse], tidymodels [@tidymodels], repr [@repr], psych [@psych], kknn [@kknn], and knitr[@knitr].

## Results

We start by loading in the raw data as seen in @tbl-raw-data. Then we processed the data and generated a summary table describing the features within the dataset, shown in @tbl-summary-stats.

```{r}
#| warning: false
#| label: tbl-raw-data
#| tbl-cap: "Raw Wine Data"
raw_white_wine <- read_csv("../data/raw/winequality-white.csv")
knitr::kable(head(raw_white_wine))
```
```{r}
#| warning: false
#| label: tbl-summary-stats
#| tbl-cap: "Summary statistics of each column in the dataset"
summ_stats <- read_csv("../results/01_summary_table_features.csv")
knitr::kable(summ_stats)
```

We can see in @tbl-summary-stats that there are no missing values as well as the summary metrics for each column. This table is generated using unscaled data so that we can use out intuition and recall the specific units of each column, gaining a better understanding of the column characteristics.

```{r}
#| warning: false
#| label: tbl-summary-stats-class
#| tbl-cap: "Summary statistics of each column by wine class"
summ_stats_class <- read_csv("../results/02_summary_table_by_class.csv")
knitr::kable(summ_stats_class)
```

From @tbl-summary-stats-class, we can see that about two-thirds of the dataset are wines under the good category, and the remaining one-third are bad wines (based on our definition of good/bad). Immediately we can see some features have similar averages between both categories and thus, those features may not be good to add in the model as they do a poor job discerning the class. However we still must consider the distributions of these features.

![Distributions of feature values between both classes of wine.](../results/03_feature_dist_plot.png){#fig-feat-dist width=90%}

In the @fig-feat-dist above, alcohol, volatile acidity, total sulfur dioxide content, density, chlorides, and residual sugar of the wines all seem to have distinct distributions for both classes of wine; the distributions have non-overlapping peaks and regions. Such features are good to add in the model because they can be used to identify one type of wine from the other.

Next, we perform hyperparamter optimization and make the train and fit the model using cross-validation to find the optimal K value for this classifier.
```{r}
#| warning: false
#| label: tbl-cv-metrics
#| tbl-cap: "Cross-validations scores for different K values"
cv_scores <- read_csv("../results/04_k_val_accuracies.csv")
best_k <- readLines("../results/05_best_k.txt")
knitr::kable(head(cv_scores))
```

![Accuracy scores for different values of K.](../results/06_accuracies_vs_k_plot.png){#fig-acc-k width=90%}

@fig-acc-k shows us that as K becomes larger, the accuracy of the model decreases. The model is overfitted at low K values and tends toward underfitting as K increases. The ideal K value for this problem seems to be around 20-25. Specifically, the best value for K is `{r} best_k`.

Finally, we use our test set to evaluate the classifier. We use several metrics to assess our model as seen below.

```{r}
#| warning: false
#| label: tbl-test-acc
#| tbl-cap: "Accuracy and other metrics for evaluating the model"
test_acc <- read_csv("../results/08_test_accuracies.csv")
knitr::kable(test_acc)
```

![Confusion Matrix.](../results/09_confusion_matrix.png){#fig-conf-mat width=70%}

@tbl-test-acc above present the accuracy, precision, and recall of our model on the test set. With an accuracy of 0.77, out model is good but can clearly be improved upon. Additionally, for the recall and precision tests, the good wine category is considered to be the positive class. We can see that the recall is high, meaning that the model has a high true positive rate (TPR). @fig-conf-mat shows the confusion matrix, further emphasizing the model assessment.

## Discussion

The wine-quality prediction model seems to do okay with the test data, having an accuracy of 0.77. It does a decent job at classifying good wines as good, where ~90% of true good wines were predicted to be good-quality. However, the model seems to not have a high true negative rate; only ~50% of true bad wines were predicted to be bad quality (as seen in @tbl-test-acc and @fig-conf-mat). We could try to increase the sensitivity of the model or further optimize it, but seeing as wine quality tends to be quite subjective and that the implications of an incorrect prediction are not severe, this model is passable as a predictor. To improve this model, we could use a more concrete and quantitative approach to feature selection and choose a metric that is suited for a 1:2 class ratio within the dataset. We could also use a different classification strategy such as SVM or Random Forest Classifier. In its current state, this model is best used as a reference where wine producers and consumers can predict wine qualities while determining the quality through other means as well.

## References